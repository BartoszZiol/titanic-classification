{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf7db8bc",
   "metadata": {},
   "source": [
    "# Titanic - Final Report and Conclusions\n",
    "## Objective\n",
    "In this section, we will summarize the key findings, evaluate feature importance,\n",
    "and discuss potential improvements for the Titanic survival prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e0930",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "1. **Data Exploration:**\n",
    "   - Women had a higher survival rate compared to men.\n",
    "   - Higher-class passengers had better chances of survival.\n",
    "   - Many missing values were found in the 'Cabin' column.\n",
    "\n",
    "2. **Feature Engineering:**\n",
    "   - Family size and social status (title) proved to be important features.\n",
    "   - Scaling and encoding categorical variables improved model performance.\n",
    "\n",
    "3. **Model Performance:**\n",
    "   - Random Forest outperformed Logistic Regression in terms of accuracy.\n",
    "   - ROC analysis revealed an acceptable trade-off between sensitivity and specificity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c168b",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "We will now analyze which features contributed the most to the Random Forest model's decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b84331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df = pd.read_csv('train_cleaned.csv')\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare', 'FamilySize', 'IsAlone', 'Embarked_Q', 'Embarked_S', 'Title_Miss', 'Title_Mr', 'Title_Mrs']\n",
    "X = train_df[features]\n",
    "y = train_df['Survived']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.DataFrame({'Feature': features, 'Importance': rf.feature_importances_})\n",
    "feature_importances.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d037c",
   "metadata": {},
   "source": [
    "## Potential Improvements\n",
    "Based on the findings, the following improvements can be considered:\n",
    "- Fine-tuning hyperparameters of models using GridSearchCV.\n",
    "- Applying advanced feature selection techniques to reduce dimensionality.\n",
    "- Using ensemble models such as Gradient Boosting and XGBoost.\n",
    "- Collecting additional data to enrich the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719f910c",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "- The Titanic dataset is a great case for learning data preprocessing and modeling.\n",
    "- Despite limitations such as missing data, useful insights were derived.\n",
    "- Further improvements in feature engineering and model selection can enhance predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c425d8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
